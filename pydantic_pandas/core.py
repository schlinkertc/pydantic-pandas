# AUTOGENERATED! DO NOT EDIT! File to edit: 00_core.ipynb (unless otherwise specified).

__all__ = ['DataFrame', 'BaseModel', 'BaseFrame', 'TypedFrame']

# Internal Cell

from pandas.core.frame import DataFrame as PandasDataFrame
from pydantic import (
    validator,
    root_validator
)
from pydantic import BaseModel as PydanticBaseModel
from pydantic.main import ModelMetaclass
from .default_standard_lib import *
from .utils import delegates
from IPython.display import JSON
from typing import Any
from pandas.api.types import pandas_dtype
from pydantic.utils import update_not_none
from pydantic import root_validator

# Cell

class DataFrame(PandasDataFrame):

    @classmethod
    def __get_validators__(cls):
        yield cls.validate

    @classmethod
    def __modify_schema__(cls,field_schema):
        field_schema.update({'type':'DataFrame'})

    @classmethod
    def validate(cls,v):
        return cls(v)

# Cell

class BaseModel(PydanticBaseModel):

    def _repr_json_(self):
        try:
            return json.loads(self.json())
        except:
            pass

    class Config:
        json_encoders = {
            DataFrame: lambda df: json.loads(df.to_json()),
            np.ndarray: lambda arr: arr.tolist(),
            pd.Series: lambda ser: json.loads(ser.to_json(date_format='iso'))
        }


# Internal Cell
_key_completions_ = list({np.dtype(k).name for k in np.typeDict.keys() if type(k)==str})

# Internal Cell

class TypedArray(pd.Series):
    dtype: Any = np.object_

    @classmethod
    def __get_validators__(cls):

        yield cls.validate_array

    @classmethod
    def __modify_schema__(cls, field_schema: Dict[str, Any]) -> None:

        update_not_none(
            field_schema,
            type='Numpy Array',
            inner_type = cls.dtype
        )

    @classmethod
    def validate_array(cls, array):
        dtype = cls.dtype

        if dtype == dt.date or dtype==dt.datetime or dtype=='datetime64':
            dtype = pandas_dtype('datetime64[ns]')

        return pd.Series(array,dtype=pandas_dtype(dtype))


#exporti

class ArrayMeta(type):
    def _ipython_key_completions_(self):
        return _key_completions_

    def __getitem__(self, dtype):

        return type('ConstrainedArray', (TypedArray,), {'dtype': dtype})


#exporti

class ConstrainedArray(DataFrame, metaclass=ArrayMeta):
    pass

# Cell

class BaseFrame(BaseModel):
    index: Any = None

#     class Config:
#         allow_population_by_field_name = True
    @root_validator
    def validate_nan(cls,values):
        df = pd.DataFrame(
            index= values.pop('index'),
            data=values,

        )

        for column,field in cls.__fields__.items():
            if field.required:
                assert df[column].isna().sum() == 0, f"required column {column} has nan values"
            elif field.default:
                df[column] = df[column].fillna(value = field.default)
        return df.reset_index().to_dict()
    @property
    def df(self):
        return pd.DataFrame(
            index=self.index,
            data = self.dict(exclude={'index'})
        )

# Internal Cell

from pydantic import ValidationError


# Cell

class TypedFrame(DataFrame):
    columns: Optional[list] = None
    row_model: Optional[Type[BaseModel]] = None

    @classmethod
    def __get_validators__(cls):
        yield cls.validate_columns
        yield cls.validate_rows

    @classmethod
    def __modify_schema__(cls, field_schema: Dict[str, Any]) -> None:
        row_model=None
        if cls.row_model:
            row_model = cls.row_model.schema()
        update_not_none(
            field_schema,
            columns=cls.columns,
            row_model=row_model
        )
    @classmethod
    def validate_columns(cls,df):
        if cls.columns:
            for c in cls.columns:
                if c not in df.columns:
                    raise ValueError(f"{c} not found in columns index: {df.columns}")
        return df

    @classmethod
    def validate_rows(cls, df):

        if cls.row_model:
            parsed = []

            for record in df.to_dict('records'):
                try:
                    model = cls.row_model.parse_obj(record)
                    parsed.append(model.dict())
                except ValidationError as e:

                    if hasattr(cls.row_model.Config,'on_error'):
                        if cls.row_model.Config.on_error=='skip':
                            continue
                    raise e

            return pd.DataFrame.from_records(parsed)
        return df

# Internal Cell

class FrameMeta(type):
    def __getitem__(self, constraint):
        if type(constraint)==tuple:
            return type('ConstrainedFrame', (TypedFrame,), {'columns': constraint})
        elif hasattr(constraint,'__get_validators__'):
            return type('ConstrainedFrame', (TypedFrame,), {'row_model': constraint})
        else:
            raise NotImplementedError(f"The constraint you provided is to compatible with the 'TypedFrame' Object. {constraint} ")


#exporti

class ConstrainedFrame(DataFrame, metaclass=FrameMeta):
    pass

# Internal Cell

def conframe(
    *,
    columns: list = None,
    row_model: Type[BaseModel] = None
) -> Type[DataFrame]:
    # use kwargs then define conf in a dict to aid with IDE type hinting
    namespace = dict(columns=columns,row_model=row_model)
    return type('ConstrainedFrameValue', (ConstrainedFrame,), namespace)